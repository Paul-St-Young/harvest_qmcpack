#!/usr/bin/env python
# Author: Yubo "Paul" Yang
# Email: yubo.paul.yang@gmail.com
#
# Scalar TABle (stab) analyzer
# `stab prefix.s000.scalar.dat -e 10 -c Kinetic` prints the mean, error and 
#  auto-correlation of the 'Kinetic' column.
#  arbitrary scalar file may be analyzed as long as it is in table format

def reblock(trace,block_size,min_nblock=4):
  nblock= len(trace)//block_size
  nkeep = nblock*block_size
  if (nblock<min_nblock):
    raise RuntimeError('only %d blocks left after reblock'%nblock)
  # end if
  blocked_trace = trace[:nkeep].reshape(nblock,block_size,*trace.shape[1:])
  return np.mean(blocked_trace,axis=1)
# end def

if __name__ == '__main__':
  import argparse
  import numpy as np
  import pandas as pd
  from qharv.reel import scalar_dat
  parser = argparse.ArgumentParser()
  parser.add_argument('fname',type=str,help='Scalar TABle (stab) file name')
  parser.add_argument('--nequil','-e',type=int,default=0
    ,help='number of equilibration blocks to throw out')
  parser.add_argument('--column','-c',type=str,default='LocalEnergy'
    ,help='name of column to analyze, to list all columns use the -l flag')
  parser.add_argument('--reblock','-rb',type=int,default=1
    ,help='reblock data to remove auto-correlation, default is 1 i.e. no reblock')
  parser.add_argument('--list','-l',action='store_true'
    ,help='list all columns available in the scalar file')
  parser.add_argument('--trace','-t',action='store_true'
    ,help='plot the trace of column')
  parser.add_argument('--append','-a',action='append',help='additional Scalar TABle (stab) file to be appended')
  args = parser.parse_args()

  df  = scalar_dat.parse(args.fname)
  # concatenate extra scalar.dat files if given by -a
  if args.append is not None:
    dlist = [df]
    for fname in args.append:
      df0 = scalar_dat.parse(fname)
      dlist.append(df0)
    # end for
    df = pd.concat(dlist).reset_index()
  # end if

  # check or override "df" here

  # interpret inputs
  if args.list:
    print(df.columns)
  if (args.column=='LocalEnergy') and ('LocalEnergy' not in df.columns):
    args.column = df.columns[0] # change default
  if args.column not in df.columns:
    raise RuntimeError('requested column "%s" not found\n available:%s'%(
        args.column,str(df.columns.values)
    ))

  # calculate the mean and error of a single column of scalars
  if args.reblock > 1:
    from qharv.sieve.scalar_df import reblock_scalar_df
    df = reblock_scalar_df(df,args.reblock)
  # end if
   
  ymean,yerr,ycorr = scalar_dat.single_column(df,args.column,args.nequil)
  
  prt_format = "{name:14s} {mean:10.6f} +/- {error:8.8f} {corr:4.2f}"
  output = prt_format.format(
    name = str(args.column),
    mean = ymean,
    error= yerr,
    corr = ycorr
    ) 
  print(output)

  if (args.trace):
    myy0= df[args.column].values
    myy = myy0[args.nequil:]
    
    import matplotlib.pyplot as plt
    fig, ax_arr = plt.subplots(1,2,sharey=True
      ,gridspec_kw = {'width_ratios':[3, 1]})

    # plot entire trace
    ax = ax_arr[0]
    ax.set_xlabel('index',fontsize=14)
    ax.set_ylabel(args.column,fontsize=14)
    ax.plot(myy0,c='k',label='')
    ax.axvline(args.nequil,c='k',ls='--',lw=2)

    # plot histogram of selected data
    ax = ax_arr[1]
    ax.set_xlabel('count',fontsize=14)
    ax.hist(myy, density=False
      , fc='gray', alpha=0.5, orientation='horizontal')
    ax.get_yaxis().tick_right() 

    # overlay statistics
    mystd = np.std(myy,ddof=1)
    for myax in ax_arr:
      myax.axhline( ymean, c='b', lw=2, label="mean = %1.6f" % ymean )
      myax.axhline( ymean+mystd, ls=":", c="gray", lw=2, label="std     = %1.6f" % mystd )
      myax.axhline( ymean-mystd, ls=":", c="gray", lw=2 )
    # end for myax
    ax_arr[0].legend(loc='best')

    fig.tight_layout()
    plt.show()
  # end if

# end __main__
